{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "xQmC7g0vG_zk"
      },
      "source": [
        "## Dataset preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z383-kW0G_zl"
      },
      "outputs": [],
      "source": [
        "import numpy as nb\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn import decomposition\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nVB_Fy3pG_zm"
      },
      "source": [
        "### Timestamp extraction\n",
        "\n",
        "Because crazy things happened in the past year,  we validated that, some specific dates had significantly higher electricity prices. Therefore we do weekday, month, and time extraction from the timestamp.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y3NmRhvzG_zm"
      },
      "outputs": [],
      "source": [
        "def extract_weekday(dataset):\n",
        "    splits = dataset['date'].astype(str).str.split('-')\n",
        "    dataset['weekday'] = [datetime.date(int(year), int(month), int(day)).weekday() for (year, month, day) in splits]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0orwSVNLG_zn"
      },
      "outputs": [],
      "source": [
        "def extract_month(dataset):\n",
        "    dataset['month'] = [month for (_, month, _) in dataset['date'].astype(str).str.split('-')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DrOWkTuHG_zn"
      },
      "outputs": [],
      "source": [
        "def extract_datetime(dataset):\n",
        "    dataset.loc[:,'time'] = pd.to_datetime(dataset.loc[:,'time'], format=\"%Y-%m-%d %H:%M:%S\", utc=True)\n",
        "    dataset['date'] = dataset['time'].dt.date\n",
        "    dataset['hour'] = dataset['time'].dt.hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dfyY0rZaG_zn"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(dataset, columns, encoder = None) -> preprocessing.OneHotEncoder:\n",
        "    if encoder:\n",
        "        transformed = encoder.transform(dataset[columns])\n",
        "    else:\n",
        "        encoder = preprocessing.OneHotEncoder(sparse= False)\n",
        "        transformed = encoder.fit_transform(dataset[columns])\n",
        "\n",
        "    new_columns = []\n",
        "    for i, column in enumerate(encoder.feature_names_in_):\n",
        "        new_columns.extend([column + str(cat) for cat in encoder.categories_[i]])\n",
        "\n",
        "    encoder_df = pd.DataFrame(transformed, index=dataset.index)\n",
        "    dataset[new_columns] = encoder_df\n",
        "    dataset.drop(columns=columns, inplace=True)\n",
        "    return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MJ63lOigG_zo"
      },
      "outputs": [],
      "source": [
        "def extract_features(dataset):\n",
        "    extract_datetime(dataset)\n",
        "    extract_month(dataset)\n",
        "    extract_weekday(dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "hN7eX9_bG_zo"
      },
      "source": [
        "### Feature dropping\n",
        "\n",
        "In Estonia, there are approximately 500\\-800 millimeters of rain on average. Our dataset consisted of only about 140mm of rain, which is definitely not correct. Also, the amount of snow was inappropriate for the  \n",
        " same reason.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wjBqWsJsG_zo"
      },
      "outputs": [],
      "source": [
        "def drop_features(dataset):\n",
        "    dataset.drop(columns=['snow','prcp','time','date'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0xEwUxN-G_zp"
      },
      "outputs": [],
      "source": [
        "def drop_rows(dataset):\n",
        "    # Deal with NaN values\n",
        "    initial_len = len(dataset)\n",
        "    dataset.dropna(inplace=True)\n",
        "    new_len = len(dataset)\n",
        "    if (initial_len != new_len):\n",
        "        print(f'Dropped {initial_len - new_len} row')\n",
        "\n",
        "    # Deal with outliners\n",
        "    dataset.drop(dataset[dataset['el_price'] > 1].index , inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ywEAPeAXG_zp"
      },
      "outputs": [],
      "source": [
        "def normalize(dataset, scaler = None) -> (pd.DataFrame, preprocessing.MinMaxScaler):\n",
        "    if scaler:\n",
        "        dataset_scaled = scaler.transform(dataset)\n",
        "        return (dataset_scaled, scaler)\n",
        "    scaler = preprocessing.MinMaxScaler()\n",
        "    dataset_scaled = scaler.fit_transform(dataset)\n",
        "    return (dataset_scaled, scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w5mvJMC5G_zp"
      },
      "outputs": [],
      "source": [
        "def reduce_dimensions(dataset, pca = None) -> (pd.DataFrame, decomposition.PCA):\n",
        "    if pca:\n",
        "        dataset_reduced = pca.transform(dataset)\n",
        "        return (dataset_reduced, pca)\n",
        "    pca = decomposition.PCA(n_components=0.9)\n",
        "    dataset_reduced = pca.fit_transform(dataset)\n",
        "    return (dataset_reduced, pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9ZgyuDOzG_zp"
      },
      "outputs": [],
      "source": [
        "def preprocess(dataset, encoder=None) -> preprocessing.OneHotEncoder:\n",
        "    extract_features(dataset)\n",
        "    drop_features(dataset)\n",
        "    encoder = one_hot_encode(dataset, ['coco', 'weekday'], encoder)\n",
        "    drop_rows(dataset)\n",
        "    return encoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5VCuq2_ZG_zp"
      },
      "source": [
        "### Import dataset\n",
        "\n",
        "Here we import dataset, do inital processing and split into train and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QrxVmltyG_zp"
      },
      "outputs": [],
      "source": [
        "def read_dataset(file_name) -> pd.DataFrame:\n",
        "    return pd.read_csv(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4M-OODkHG_zq"
      },
      "outputs": [],
      "source": [
        "def extract_labels(dataset) -> (pd.DataFrame, pd.Series):\n",
        "    X_train = dataset.loc[:, ~dataset.columns.isin(['consumption'])]\n",
        "    y_train = dataset['consumption']\n",
        "    return (X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86ZWVt3pG_zq",
        "outputId": "df921390-b85b-46a9-85c2-0908d208cb81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped 2 row\n"
          ]
        }
      ],
      "source": [
        "train_df = read_dataset('train.csv')\n",
        "encoder = preprocess(train_df)\n",
        "\n",
        "\n",
        "X_train, y_train = extract_labels(train_df)\n",
        "\n",
        "X_train_norm, scaler = normalize(X_train)\n",
        "X_train_reduced, pca = reduce_dimensions(X_train_norm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtaKcoPHG_zq",
        "outputId": "bcba3a6d-c65e-40ea-a90f-2b0b047d5a98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8588, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "X_train_norm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJQrBk77G_zr",
        "outputId": "eecc2740-7c65-4698-fcfe-1c69cbe156e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(168, 41)\n"
          ]
        }
      ],
      "source": [
        "X_test = read_dataset('test.csv')\n",
        "preprocess(X_test, encoder)\n",
        "\n",
        "X_test_norm, _ = normalize(X_test, scaler)\n",
        "print(X_test_norm.shape)\n",
        "X_test_reduced, _ = reduce_dimensions(X_test_norm, pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ASksVPZVG_zr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_reduced, y_train, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPrlZDSjG_zr",
        "outputId": "f58f68b3-f9a0-4240-92f8-1407ff8c93c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6870, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-EZWjw3iG_zr"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "# Numpy\n",
        "import numpy as np\n",
        "\n",
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "\n",
        "# Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Sklearn\n",
        "import sklearn.preprocessing\n",
        "import sklearn.utils\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Visualiseerimine\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "icZedCGnG_zr"
      },
      "outputs": [],
      "source": [
        "#reg = xgb.XGBRegressor(tree_method=\"gpu_hist\")\n",
        "# Fit the model using predictor X and response y."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoosts wants data to be wrapped into special formats\n",
        "#dtrain = xgb.DMatrix(X_train,label=y_train)\n",
        "#dval = xgb.DMatrix(X_val,label=y_val)\n",
        "#dtest = xgb.DMatrix(X_test_reduced)"
      ],
      "metadata": {
        "id": "mWPVs62p5z_O"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgbr = xgb.XGBRegressor(verbosity=0)"
      ],
      "metadata": {
        "id": "_3kpgK8S7Bas"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgbr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "XHlWKJmX8Ucf",
        "outputId": "ce446cd3-1575-449c-941b-454719780fc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(verbosity=0)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yvalpred = xgbr.predict(X_val)\n",
        "mse = mean_squared_error(y_val, yvalpred)\n",
        "print(\"MSE: %.2f\" % mse)"
      ],
      "metadata": {
        "id": "MYctyJLg8pyR",
        "outputId": "770f94fd-4a90-4055-8604-f325032c3f67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = xgbr.predict(X_test_reduced)"
      ],
      "metadata": {
        "id": "dptGtBsYHYVv"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1wUYiZyJFSi",
        "outputId": "53e6170b-db2e-4c94-ee8c-188fdd5feb9d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.62187433, 0.75440955, 0.62187433, 0.66751933, 0.6425308 ,\n",
              "       0.71292907, 0.6462215 , 0.52454984, 0.4854585 , 0.7375344 ,\n",
              "       0.65172505, 0.46956855, 0.46956855, 0.6344147 , 0.78201   ,\n",
              "       0.93963426, 0.6133261 , 0.812935  , 0.91216516, 0.75446105,\n",
              "       0.81961656, 0.9321583 , 0.7963561 , 0.7827731 , 0.7443634 ,\n",
              "       0.6932913 , 0.6932913 , 0.65665776, 0.6044201 , 0.6044201 ,\n",
              "       0.5616169 , 0.63849294, 0.6188985 , 0.58194673, 0.69731253,\n",
              "       0.6666155 , 0.598039  , 0.72141546, 0.54217297, 0.8621993 ,\n",
              "       0.54217297, 0.54217297, 0.6915774 , 0.7110124 , 0.6073897 ,\n",
              "       0.63762325, 0.6825634 , 0.7646626 , 0.67939097, 0.5506639 ,\n",
              "       0.5369478 , 0.8143346 , 0.65855944, 0.65855944, 0.6716348 ,\n",
              "       0.65543866, 0.6602229 , 0.764709  , 0.6200744 , 0.97568333,\n",
              "       0.87496567, 0.87496567, 0.9688145 , 1.0166875 , 0.80761695,\n",
              "       0.77413523, 0.9235763 , 1.1156735 , 1.1156735 , 1.0596904 ,\n",
              "       0.98011816, 0.64114666, 0.5733334 , 0.5685491 , 0.662343  ,\n",
              "       0.7841406 , 0.62836546, 0.5610234 , 0.64144087, 0.70958287,\n",
              "       0.7478243 , 0.73085827, 0.7235136 , 0.7676198 , 0.7220508 ,\n",
              "       0.7021374 , 0.6580313 , 1.1429381 , 1.5279133 , 0.965549  ,\n",
              "       0.95567137, 0.9508871 , 0.92144287, 0.7585441 , 0.74982464,\n",
              "       0.7585441 , 0.72496766, 0.74594486, 0.6450838 , 0.7593751 ,\n",
              "       0.635966  , 0.635966  , 0.64904135, 0.64054537, 0.56838477,\n",
              "       0.62261045, 0.5442666 , 0.5442666 , 0.6449842 , 0.47257328,\n",
              "       0.7191182 , 0.8393577 , 0.5742256 , 0.55943215, 0.8168632 ,\n",
              "       0.9411843 , 0.9578907 , 0.9102167 , 0.66211456, 0.72775745,\n",
              "       0.72775745, 0.8355355 , 0.6524478 , 0.81104946, 0.76033175,\n",
              "       0.7250343 , 0.73549646, 0.8038337 , 0.71705127, 0.6209256 ,\n",
              "       0.63187283, 0.5308003 , 0.5308003 , 0.41211605, 0.65752196,\n",
              "       0.62163335, 0.8538165 , 0.7489321 , 1.1286354 , 0.955472  ,\n",
              "       0.84641707, 0.9449403 , 0.819667  , 0.9550619 , 0.754367  ,\n",
              "       0.740784  , 0.740784  , 0.6428893 , 0.76276827, 0.70384425,\n",
              "       0.66349626, 0.65399635, 0.6427925 , 0.5904743 , 0.54532075,\n",
              "       0.636009  , 0.636009  , 1.1058829 , 0.7918718 , 1.1804694 ,\n",
              "       0.9853966 , 1.1309155 , 1.0405407 , 1.0284353 , 0.98905665,\n",
              "       0.95706105, 0.9119842 , 0.90933645], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = read_dataset('test.csv')"
      ],
      "metadata": {
        "id": "dNcUV4NELuj3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_dict = {'time':X_test.time,'consumption':prediction}\n",
        "pred_df = pd.DataFrame(predictions_dict)\n",
        "pred_df.to_csv('submission_Xgboost_v1.csv',index=False)"
      ],
      "metadata": {
        "id": "XKzfaUpNJtQE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GsOI3JeXLokg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (system-wide)",
      "language": "python",
      "metadata": {
        "cocalc": {
          "description": "Python 3 programming language",
          "priority": 100,
          "url": "https://www.python.org/"
        }
      },
      "name": "python3",
      "resource_dir": "/ext/jupyter/kernels/python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}